# cd .\source\ ; pip install . ; cd .. ; python ./test.py

import os
import sys
import time

import h5py
import nndescent_m
import numpy as np
import scipy.sparse
from sklearn import neighbors


class NNDescentM:
    def __init__(self, metric, index_param_dict):
        if "n_neighbors" in index_param_dict:
            self.n_neighbors = int(index_param_dict["n_neighbors"])
        else:
            self.n_neighbors = 30

        if "pruning_degree_multiplier" in index_param_dict:
            self.pruning_degree_multiplier = float(index_param_dict["pruning_degree_multiplier"])
        else:
            self.pruning_degree_multiplier = 1.5

        if "pruning_prob" in index_param_dict:
            self.pruning_prob = float(index_param_dict["pruning_prob"])
        else:
            self.pruning_prob = 1.0

        if "leaf_size" in index_param_dict:
            self.leaf_size = int(index_param_dict["leaf_size"])

        self.is_sparse = metric in ["jaccard"]

        self.nnd_metric = {
            "angular": "angular",
            "euclidean": "euclidean",
            # "hamming": "hamming",
            # "jaccard": "jaccard",
        }[metric]

    def fit(self, X):
        if self.is_sparse:
            # Sparse matrix conversion logic...
            # (Keeping existing logic roughly same, assuming X is dense for typical tests)
            pass
        elif not isinstance(X, np.ndarray) or X.dtype != np.float32:
            print("Convert data to float32")
            X = np.asarray(X, dtype=np.float32)

        self.X = X
        with nndescent_m.ostream_redirect(stdout=True, stderr=True):
            self.index = nndescent_m.NNDescent(
                metric=self.nnd_metric,
                n_neighbors=self.n_neighbors,
                pruning_degree_multiplier=self.pruning_degree_multiplier,
                pruning_prob=self.pruning_prob,
                leaf_size=getattr(self, "leaf_size", 32),
            )

        with nndescent_m.ostream_redirect(stdout=True, stderr=True):
            self.index.fit(self.X)

    def set_query_arguments(self, epsilon=0.1):
        self.epsilon = float(epsilon)

    def query(self, v, n):
        # è½¬æ¢æŸ¥è¯¢å‘é‡ä¸º float32
        v_f32 = v.reshape(1, -1).astype("float32")

        # ä¿®æ­£ï¼šC++ åªè¿”å›äº† indices (std::vector<uint32_t>)
        # ä¸éœ€è¦æ¥æ”¶ dist
        with nndescent_m.ostream_redirect(stdout=True, stderr=True):
            ind = self.index.query(v_f32, k=n, epsilon=self.epsilon)
        return ind  # BaseANN æœŸæœ›è¿”å›ç´¢å¼•åˆ—è¡¨

    def batch_query(self, X, n):
        if X.dtype != np.float32:
            X = X.astype(np.float32)
        if not X.flags["C_CONTIGUOUS"]:
            X = np.ascontiguousarray(X)

        with nndescent_m.ostream_redirect(stdout=True, stderr=True):
            self.res = self.index.batch_query(X, k=n, epsilon=self.epsilon)

    def get_batch_results(self):
        return self.res

    def __str__(self):
        return (
            f"NNDescentM(n_neighbors={self.n_neighbors}, "
            f"pruning_mult={self.pruning_degree_multiplier:.2f}, "
            f"pruning_prob={self.pruning_prob:.3f}, "
            f"leaf_size={getattr(self, 'leaf_size', 32)}, "
            f"metric={self.nnd_metric})"
        )


def test(X_train, X_test, ground_truth, distance_metric, batch_query=False):
    # åˆå§‹åŒ–ç®—æ³•
    params = {"n_neighbors": 40, "pruning_degree_multiplier": 1.5, "pruning_prob": 1.0, "leaf_size": 25}

    print("\n[1/3] åˆå§‹åŒ–ä¸æ„å»ºç´¢å¼• (Fit)...")
    algo = NNDescentM(distance_metric, params)

    start_time = time.time()
    algo.fit(X_train)
    print(f"æ„å»ºè€—æ—¶: {time.time() - start_time:.4f} ç§’")

    print(f"æ„å»ºç»“æœï¼š\n{algo}")

    print("\n[2/3] æ‰§è¡ŒæŸ¥è¯¢ (Query)...")
    algo.set_query_arguments(epsilon=0.12)

    k = 10
    hits = 0
    total = 0

    total_queries = len(X_test)
    query_start_time = time.time()

    if batch_query:
        algo.batch_query(X_test, k)
        predicted_batch = algo.get_batch_results()
        for i in range(len(X_test)):
            predicted_ids = predicted_batch[i]
            true_ids = set(ground_truth[i][:k])
            predicted_set = set(predicted_ids)

            intersection = true_ids.intersection(predicted_set)
            hits += len(intersection)
            total += k

            if i == 0:
                print("\n  [ç¤ºä¾‹ Query #0]")
                print(f"  é¢„æµ‹: {predicted_ids}")
                print(f"  çœŸå€¼: {true_ids}")
                print(f"  é‡åˆ: {intersection}/{k}")
    else:
        for i in range(len(X_test)):
            query_vec = X_test[i]
            predicted_ids = algo.query(query_vec, k)

            true_ids = set(ground_truth[i][:k])
            predicted_set = set(predicted_ids)

            intersection = true_ids.intersection(predicted_set)
            hits += len(intersection)
            total += k

            if i == 0:
                print("\n  [ç¤ºä¾‹ Query #0]")
                print(f"  é¢„æµ‹: {predicted_ids}")
                print(f"  çœŸå€¼: {true_ids}")
                print(f"  é‡åˆ: {intersection}/{k}")

    print(f"\n[3/3] ç»“æœéªŒè¯...")

    recall = hits / total

    query_total_time = time.time() - query_start_time
    qps = total_queries / query_total_time

    print("-" * 50)
    print("ğŸ† æœ€ç»ˆç»“æœ (Swiss Roll Dataset):")
    print(f"   Recall@{k} : {recall:.4f}")
    print(f"   QPS        : {qps:.2f} queries/s")
    print("-" * 50)

    if recall > 0.5:
        print("\nâœ… æµ‹è¯•é€šè¿‡ï¼ä½ çš„ NNDescentM å·²ç»å¯ä»¥å·¥ä½œäº†ã€‚")
        print("ä¸‹ä¸€æ­¥ï¼šå°è¯•è¿è¡Œ python run.py --algorithm nndescent_m --dataset glove-100-angular")
    else:
        print("\nâš ï¸ å¬å›ç‡è¾ƒä½ï¼Œè¯·æ£€æŸ¥ C++ çš„è·ç¦»è®¡ç®—æˆ–æ„å»ºå‚æ•°ã€‚")


def load_hdf5_and_test(filename, batch_query=False):
    print(f"æ­£åœ¨è¯»å– {filename} ...")
    with h5py.File(filename, "r") as f:
        X_train = np.array(f["train"])
        X_test = np.array(f["test"])
        ground_truth = np.array(f["neighbors"])
        distance_metric = f.attrs["distance"]

    print(f"æ•°æ®åŠ è½½å®Œæ¯•: Train={X_train.shape}, Test={X_test.shape}, Metric={distance_metric}")

    test(X_train, X_test, ground_truth, distance_metric, batch_query)


def generate_and_test(batch_query=False):
    from sklearn.datasets import make_swiss_roll
    from sklearn.model_selection import train_test_split
    from sklearn.neighbors import NearestNeighbors

    print("ç”Ÿæˆ Swiss Roll æ•°æ®é›†...")
    X, _ = make_swiss_roll(n_samples=10000, noise=0.1)
    X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)

    # è®¡ç®—çœŸå®é‚»å±…
    nbrs = NearestNeighbors(n_neighbors=10, algorithm="brute", metric="cosine").fit(X_train)
    distances, indices = nbrs.kneighbors(X_test)

    print("æ•°æ®é›†å‚æ•°ï¼š")
    print(f"  è®­ç»ƒé›†å¤§å°: {X_train.shape}")
    print(f"  æµ‹è¯•é›†å¤§å°: {X_test.shape}")
    print(f"  è·ç¦»åº¦é‡: angular")

    test(X_train, X_test, indices, distance_metric="angular", batch_query=batch_query)


if __name__ == "__main__":
    test_file = "C:\\Users\\31070\\Desktop\\PROGRAMS\\db\\ann-benchmarks\\data\\mnist-784-euclidean.hdf5"
    # test_file = "C:\\Users\\31070\\Desktop\\PROGRAMS\\db\\ann-benchmarks\\data\\glove-100-angular.hdf5"
    load_hdf5_and_test(test_file, batch_query=True)
    # load_hdf5_and_test(test_file, batch_query=False)

    # generate_and_test()
